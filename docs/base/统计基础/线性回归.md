# 线性回归（linear regression）

**什么是回归？**

回归的目的是为了预测，比如预测明天的天气温度，预测股票的走势…

回归之所以能预测是因为他通过历史数据，摸透了“套路”，然后通过这个套路来预测未来的结果。

**什么是线性？**

“越…，越…”符合这种说法的就可能是线性个关系：

「房子」越大，「租金」就越高

「汉堡」买的越多，花的「钱」就越多

杯子里的「水」越多，「重量」就越大

……

但是并非所有“越…，越…”都是线性的，比如“充电越久，电量越高”，他就类似下面的非线性曲线：

<img src="http://img.elixir-zh.cn/uPic/image-20200413113806836.png" alt="image-20200413113806836" style="zoom:50%;" />

线性关系不仅仅只能存在 2 个变量（二维平面）。3 个变量时（三维空间），线性关系就是一个平面，4 个变量时（四维空间），线性关系就是一个体。以此类推…

<img src="http://img.elixir-zh.cn/uPic/image-20200413113954497.png" alt="image-20200413113954497" style="zoom:50%;" />



在**统计学**中，线性回归是一种线性方法，用于建模标量响应（或因变量）与一个或多个解释变量（或独立变量）之间的关系。

一个解释变量，称为简单线性回归。

多个解释变量，称为多元线性回归。

该术语不同于多元线性回归，其中预测了多个相关因变量，而不是单个标量变量。

在线性回归中，使用线性预测函数对关系进行建模，其中未知模型参数是根据数据估计的。

这种模型称为线性模型。

最常见的是，给定解释变量（或预测变量）的值的响应的条件均值被假定为这些值的仿射函数 ; 不太常见的是，使用条件中值或一些其他分位数。

与所有形式的回归分析一样，线性回归侧重于条件概率分布给出预测变量值的响应，而不是所有这些变量的联合概率分布，这是多变量分析的领域。



## 协方差（Covanriance）

### 方差 VS 协方差

- 方差：刻画一个数值变量偏离其中心的程度
  $$
  Var(X)=\frac{\sum{^n_{i=1}}(X_i-X)^2}{n-1}
  $$
  

- 协方差：刻画两个数值变量共同变化的程度
  $$
  Cov(X,Y)=\frac{\sum{^n_{i=1}}(X_i-X)(Y_i-Y)}{n-1}
  $$

> ps：协方差的取值与数据严格相关。无法单一判断。
>
> 解决办法是引入“相关系数”





## 相关（Correlation）

相关系数 r
$$
r=\frac{Cov(X,Y)}{S_xS_y}
$$
$S_x$变量 X 的标准差

$S_y$变量 Y 的标准差

- 描述两个数值变量**线性**关系的**强度**和**方向**
- 取值范围-1 ≤ r ≤ 1
- r 的绝对值大小代表线性关系的强弱

<img src="http://img.elixir-zh.cn/uPic/image-20200413211043970.png" alt="image-20200413211043970" style="zoom:50%;" />

- r 的符号代表线性关系的方向
- r = 0：没有线性关系 ≠ 没有关系
  <img src="http://img.elixir-zh.cn/uPic/image-20200413211242120.png" alt="image-20200413211242120" style="zoom:50%;" />

- r = 1：完美线性正相关；r = -1：完美线性负相关；
- r 没有单位，不受变量平移伸缩的影响
- X，Y的相关系数=Y，X的相关系数
- **r 受极端值影响大**

> [编程实现](https://github.com/Terry-bear/algorithm-100/blob/master/statistics/stats/descriptive_stats.py)



## 一元线性回归

- 两个变量之间的线性关系及其统计显著性
- 两个变量：一个因变量，一个自变量
- 给定自变量的值，预测因变量的值

<img src="http://img.elixir-zh.cn/uPic/image-20200413215217277.png" alt="image-20200413215217277" style="zoom:50%;" />

<img src="http://img.elixir-zh.cn/uPic/image-20200413221009173.png" alt="image-20200413221009173" style="zoom:50%;" />

线性关系的方向和强度一样：回归直线拟合数据的好坏

左侧斜率大（Sy/Sx大），右侧斜率小（Sy/Sx 小）：x 变化一个单位，y 变化的大小



- 线性（linearity）：自变量和因变量之间的关系是线性的
  - 使用散点图或残差图来检验
    <img src="http://img.elixir-zh.cn/uPic/image-20200413222650841.png" alt="image-20200413222650841" style="zoom: 67%;" />
- 残差（近似）服从均值为 0的正太分布
  - 使用频率直方图来检验
- 数据点围绕回归直线的变化程度基本不变（variability constant）
  - 残差围绕直线 y=0 的变化程度基本不变
    <img src="http://img.elixir-zh.cn/uPic/image-20200413223009051.png" alt="image-20200413223009051" style="zoom:50%;" />
    <img src="http://img.elixir-zh.cn/uPic/image-20200413223050392.png" alt="image-20200413223050392" style="zoom:50%;" />

### 回归模型的评价指标

#### RMSE

<img src="http://img.elixir-zh.cn/uPic/image-20200413223344550.png" alt="image-20200413223344550" style="zoom:33%;" />

#### $R^2$

<img src="http://img.elixir-zh.cn/uPic/image-20200413223456021.png" alt="image-20200413223456021" style="zoom:33%;" />

<img src="http://img.elixir-zh.cn/uPic/image-20200413223800430.png" alt="image-20200413223800430" style="zoom:33%;" />



## 一元线性回归中的假设检验

[编程实现](https://github.com/Terry-bear/algorithm-100/blob/master/statistics/stats/descriptive_stats.py)

